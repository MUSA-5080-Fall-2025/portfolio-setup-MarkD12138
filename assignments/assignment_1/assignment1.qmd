---
title: "Assignment 1: Census Data Quality for Policy Decisions"
subtitle: "Evaluating Data Reliability for Algorithmic Decision-Making"
author: "Zimu DENG (Mark)"
date: today
format: 
  html:
    code-fold: false
    toc: true
    toc-location: left
    theme: cosmo
execute:
  warning: false
  message: false
---

# Assignment Overview

## Scenario

You are a data analyst for the **Pennsylvania Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.

Drawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.

## Learning Objectives

- Apply dplyr functions to real census data for policy analysis
- Evaluate data quality using margins of error 
- Connect technical analysis to algorithmic decision-making
- Identify potential equity implications of data reliability issues
- Create professional documentation for policy stakeholders

## Submission Instructions

**Submit by posting your updated portfolio link on Canvas.** Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/`

Make sure to update your `_quarto.yml` navigation to include this assignment under an "Assignments" menu.

# Part 1: Portfolio Integration

Create this assignment in your portfolio repository under an `assignments/assignment_1/` folder structure. Update your navigation menu to include:

```
- text: Assignments
  menu:
    - href: assignments/assignment_1/your_file_name.qmd
      text: "Assignment 1: Census Data Exploration"
```
If there is a special character like comma, you need use double quote mark so that the quarto can identify this as text

# Setup

```{r setup}
# Load required packages (hint: you need tidycensus, tidyverse, and knitr)
library(tidycensus)
library(tidyverse)
library(knitr)

# Set your Census API key
census_api_key("cd859f2a38103dda55948d92b3679de845f42f0f")

# Choose your state for analysis - assign it to a variable called my_state
my_state <- "PA"
```

**State Selection:** I have chosen **Pennsylvania** for this analysis because: I currently live and study here, so understanding the data quality and its implications for local communities is directly relevant to my daily life and policy understanding.

# Part 2: County-Level Resource Assessment

## 2.1 Data Retrieval

**Your Task:** Use `get_acs()` to retrieve county-level data for your chosen state.

**Requirements:**
- Geography: county level
- Variables: median household income (B19013_001) and total population (B01003_001)  
- Year: 2022
- Survey: acs5
- Output format: wide

**Hint:** Remember to give your variables descriptive names using the `variables = c(name = "code")` syntax.

```{r county-data}
# Write your get_acs() code here
PA_data <- get_acs(
  geography = "county",
  variables = c(
    total_pop = "B01003_001",
    median_income = "B19013_001"
  ),
  state = my_state,
  year = 2022,
  survey = "acs5",
  output = "wide"
)

# Clean the county names to remove state name and "County" 
# Hint: use mutate() with str_remove()
PA_clean <- PA_data %>%
  mutate(
    NAME = str_remove(NAME, "County, Pennsylvania")
  )
  
# Display the first few rows
glimpse(PA_clean)
head(PA_clean)
```

## 2.2 Data Quality Assessment

**Your Task:** Calculate margin of error percentages and create reliability categories.

**Requirements:**
- Calculate MOE percentage: (margin of error / estimate) * 100
- Create reliability categories:
  - High Confidence: MOE < 5%
  - Moderate Confidence: MOE 5-10%  
  - Low Confidence: MOE > 10%
- Create a flag for unreliable estimates (MOE > 10%)

**Hint:** Use `mutate()` with `case_when()` for the categories.

```{r income-reliability}
# Calculate MOE percentage and reliability categories using mutate()
PA_reliability <- PA_clean %>%
  mutate(
    MOE = (median_incomeM / median_incomeE) * 100,
    re_categories = case_when(
      MOE < 5 ~ "High Confidence",
      MOE >= 5 & MOE <= 10 ~ "Moderate Confidence",
      TRUE ~ "Low Confidence"
    ),
    unreliable_flag = MOE > 10
  )

# Create a summary showing count of counties in each reliability category
# Hint: use count() and mutate() to add percentages
PA_reliability_summary <- PA_reliability %>%
  count(re_categories) %>%   
  mutate(
    percent = n / sum(n) * 100   
  )

PA_reliability_summary
```

## 2.3 High Uncertainty Counties

**Your Task:** Identify the 5 counties with the highest MOE percentages.

**Requirements:**
- Sort by MOE percentage (highest first)
- Select the top 5 counties
- Display: county name, median income, margin of error, MOE percentage, reliability category
- Format as a professional table using `kable()`

**Hint:** Use `arrange()`, `slice()`, and `select()` functions.

```{r high-uncertainty}
# Create table of top 5 counties by MOE percentage
reliability_sort <- PA_reliability %>%
  arrange(desc(MOE))

Top5_county <- reliability_sort %>%
  slice_head(n = 5) %>%
  select(NAME,          
         median_incomeE,
         median_incomeM,
         MOE,
         re_categories)

# Format as table with kable() - include appropriate column names and caption
kable(Top5_county, 
      align = c("l","l","l","l","l"),
      col.names = c("County", "Medain Income", "Margin of Error", "MOE(%)", "Reliability Category"),
      caption = "Top 5 Counties by MOE Percentage")
```

**Data Quality Commentary:**

Counties with higher MOE values are more likely to be inaccurately represented in algorithmic decision-making due to the lower reliability of their income data. This means that decisions based on such data may carry systematic bias. For instance, counties with higher MOE may have lower true median incomes that go undetected, leading to missed opportunities for support or resource allocation. This uncertainty may arise because many lower-income residents in these counties are harder to reach or less likely to participate in surveys.

# Part 3: Neighborhood-Level Analysis

## 3.1 Focus Area Selection

**Your Task:** Select 2-3 counties from your reliability analysis for detailed tract-level study.

**Strategy:** Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.

```{r select-counties}
# Use filter() to select 2-3 counties from your county_reliability data
# Store the selected counties in a variable called selected_counties
selected_counties <- reliability_sort %>%
  filter(str_detect(NAME, "Philadelphia") | str_detect(NAME, "Warren")) %>%
  select(NAME,          
         median_incomeE,
         MOE,
         re_categories)

# Display the selected counties with their key characteristics
# Show: county name, median income, MOE percentage, reliability category
kable(selected_counties, 
      align = c("l","l","l","l"),
      col.names = c("County", "Medain Income", "MOE(%)", "Reliability Category"),
      caption = "Two Selected Counties")

```

**Comment on the output:** Warren and Philadelphia are selected that represent different reliability levels to do further analysis in tract-level study.

## 3.2 Tract-Level Demographics

**Your Task:** Get demographic data for census tracts in your selected counties.

**Requirements:**
- Geography: tract level
- Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001)
- Use the same state and year as before
- Output format: wide
- **Challenge:** You'll need county codes, not names. Look at the GEOID patterns in your county data for hints.

```{r tract-demographics}
# Define your race/ethnicity variables with descriptive names
# Use get_acs() to retrieve tract-level data
# Hint: You may need to specify county codes in the county parameter
County_data <- get_acs(
  geography = "tract",
  variables = c(
    White_Alone = "B03002_003",
    Black_American = "B03002_004",
    Hispanic_Latino = "B03002_012",
    total_population = "B03002_001"
  ),
  state = 42,
  county = c("101", "123"),
  year = 2022,
  survey = "acs5",
  output = "wide"
)

# Calculate percentage of each group using mutate()
# Create percentages for white, Black, and Hispanic populations
County_data <- County_data %>%
  mutate(
    pct_white   = 100 * White_AloneE / total_populationE,
    pct_black   = 100 * Black_AmericanE / total_populationE,
    pct_hispanic= 100 * Hispanic_LatinoE / total_populationE
  )

# Add readable tract and county name columns using str_extract() or similar
County_data <- County_data %>%
  mutate(
    county = str_extract(NAME, "(?<=; )[^;]+(?= County)"), 
    tract  = str_extract(NAME, "(?<=Census )[^;]+")
  )
```

## 3.3 Demographic Analysis

**Your Task:** Analyze the demographic patterns in your selected areas.

```{r demographic-analysis}
# Find the tract with the highest percentage of Hispanic/Latino residents
# Hint: use arrange() and slice() to get the top tract
Top_his <- County_data %>%
  arrange(desc(pct_hispanic)) %>%
  slice_head(n=1)

# Calculate average demographics by county using group_by() and summarize()
# Show: number of tracts, average percentage for each racial/ethnic group
county_summary <- County_data %>%
  group_by(county) %>%
  summarize(
    n_tracts = n(),
    avg_white = weighted.mean(pct_white, total_populationE, na.rm = TRUE),
    avg_black = weighted.mean(pct_black, total_populationE, na.rm = TRUE),
    avg_hispanic = weighted.mean(pct_hispanic, total_populationE, na.rm = TRUE) 
)

# Create a nicely formatted table of your results using kable()
kable(county_summary, 
      align = c("l","l","l","l"),
      col.names = c(
        "County", "Tracts Number", "Average White Proportion", "Average Black Proportion", "Average Hispanic Proportion"),
      caption = "Average Racial Demographics by County")

```

# Part 4: Comprehensive Data Quality Evaluation

## 4.1 MOE Analysis for Demographic Variables

**Your Task:** Examine margins of error for demographic variables to see if some communities have less reliable data.

**Requirements:**
- Calculate MOE percentages for each demographic variable
- Flag tracts where any demographic variable has MOE > 15%
- Create summary statistics

```{r demographic-moe}
# Calculate MOE percentages for white, Black, and Hispanic variables
# Hint: use the same formula as before (margin/estimate * 100)
tract_MOE <- County_data %>%
  mutate(
    MOE_white = (White_AloneM / White_AloneE) * 100,
    MOE_black = (Black_AmericanM / Black_AmericanE) * 100,
    MOE_hispanic = (Hispanic_LatinoM / Hispanic_LatinoE) * 100
  )

# Create a flag for tracts with high MOE on any demographic variable
# Use logical operators (| for OR) in an ifelse() statement
tract_MOE <- tract_MOE %>%
  mutate(
    flag = ifelse(
    MOE_white > 15 | MOE_black > 15 | MOE_hispanic > 15,
    1,
    0
  )
)

# Create summary statistics showing how many tracts have data quality issues
tract_issue_summary <- tract_MOE %>%
  group_by(county) %>%
  summarize(
    n_tracts = n(),
    quality_issues_count = sum(flag)
  )
tract_issue_summary

summary(tract_MOE$MOE_white)
summary(tract_MOE$MOE_black)
summary(tract_MOE$MOE_hispanic)
```
**Discussion:** This result indicates that at the tract level, the population estimates for different racial/ethnic groups have relatively large margins of error, reflecting substantial sampling error at this scale.

## 4.2 Pattern Analysis

**Your Task:** Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.

```{r pattern-analysis}
# Group tracts by whether they have high MOE issues
# Calculate average characteristics for each group:
# - population size, demographic percentages

## Since all tracts in my selected data have MOE issues where at least 1 demographic variable has MOE > 15%, I select to use the count of demographic variable has MOE > 15% to present the severity of MOE issues
tract_MOE2 <- tract_MOE %>%
  mutate(
    high_white    = MOE_white    > 15,
    high_black    = MOE_black    > 15,
    high_hispanic = MOE_hispanic > 15,
    high_count    = high_white + high_black + high_hispanic,  
    severity      = case_when(
      high_count == 3 ~ "High",
      high_count == 2 ~ "Moderate",
      TRUE            ~ "Low"
    )
  )

# Use group_by() and summarize() to create this comparison
# Create a professional table showing the patterns
pattern_tbl <- tract_MOE2 %>%
  group_by(severity) %>%
  summarise(
    n_tracts = n(),
    pop      = mean(total_populationE, na.rm = TRUE),
    avg_white = weighted.mean(pct_white, total_populationE, na.rm = TRUE),
    avg_black = weighted.mean(pct_black, total_populationE, na.rm = TRUE),
    avg_hispanic = weighted.mean(pct_hispanic, total_populationE, na.rm = TRUE),
  ) 

kable(pattern_tbl, 
      align = c("l","l","l","l","l"), 
      col.names = c("Severity", "Tracts Number", "Average Population", "Average White Proportion", "Average Black Proportion", "Average Hispanic Proportion"),
      caption = "Pattern of tarcts with different severity of MOE issues")
```

**Pattern Analysis:** Tracts with high severity of MOE issues have similar average population sizes compared to those in the moderate group. However, they show much lower average White population share and higher average Black and Hispanic population shares. This suggests that tracts with higher proportions of Black and Hispanic residents tend to have less reliable estimated data. One likely explanation is that these communities face structural challenges in survey data collection, including lower response rates and higher nonresponse bias. Such challenges may stem from factors such as longer work hours, higher population mobility, and language or cultural barriers among immigrant households, which are caused by historical reasons.


# Part 5: Policy Recommendations

## 5.1 Analysis Integration and Professional Summary

**Your Task:** Write an executive summary that integrates findings from all four analyses.

**Executive Summary Requirements:**
1. **Overall Pattern Identification**: What are the systematic patterns across all your analyses?
2. **Equity Assessment**: Which communities face the greatest risk of algorithmic bias based on your findings?
3. **Root Cause Analysis**: What underlying factors drive both data quality issues and bias risk?
4. **Strategic Recommendations**: What should the Department implement to address these systematic issues?

**Executive Summary:**

**Overall Pattern Identification**: Overall, MOE values are generally within acceptable bounds at the county level, indicating good reliability for income estimates. But uncertainty is pervasive at the tract level: every tract in two selected counties has at least one racial subgroup with MOE > 15%, and “high-severity” tracts (where multiple subgroups exceed the threshold) are common. These tracts with severe MOE issues exhibit markedly lower average White share and higher Black and Hispanic shares.

**Equity Assessment**: Because MOE is systematically larger in tracts with higher proportions of Black and Hispanic residents, algorithms that rely on these estimates might have issues of mis-classification and under-allocation of resources. Counties and neighborhoods with greater shares of Black and Hispanic populations, which potentially have lower true median incomes, are more likely to be labeled with uncertain data and thus underserved, amplifying pre-existing inequities.

**Root Cause Analysis**: Firstly, smaller subgroup of data at the tract scale naturally owns a smaller sample size, and smaller samples tends to have higher uncertainty. Moreover, in these communities with greater shares of Black and Hispanic residents, due to historical reasons, the residents might face difficulties including language and cultural barriers, time constraints from multiple jobs or long shifts. These difficulties might lead to lower response rates and higher nonresponse bias, raising the issue of MOE and uncertainty of data.

**Strategic Recommendations**: For tracts with lower data reliability (MOE exceeds 15%), the data should not be used directly for algorithmic decision-making; instead, these cases should be referred for manual review. In the long term, efforts should focus on improving data precision in these areas to enhance reliability and, simultaneously, refining algorithms to apply adjusted weighting for high-MOE regions. These measures would improve both the accuracy and fairness of data-driven decisions.

## 5.2 Specific Recommendations

**Your Task:** Create a decision framework for algorithm implementation.

```{r recommendations-data}
# Create a summary table using your county reliability data
# Include: county name, median income, MOE percentage, reliability category
Summary_tbl <- PA_reliability %>%
  summarize(
    county_name = NAME,
    median_income = median_incomeE,
    MOE_percentage = MOE,
    reliability_category = re_categories
  )

# Add a new column with algorithm recommendations using case_when():
# - High Confidence: "Safe for algorithmic decisions"
# - Moderate Confidence: "Use with caution - monitor outcomes"  
# - Low Confidence: "Requires manual review or additional data"
Summary_tbl <- Summary_tbl %>%
  mutate(
    algorithm_recommendations = case_when(
      reliability_category == "High Confidence" ~ "Safe for algorithmic decisions",
      reliability_category == "Moderate Confidence" ~ "Use with caution - monitor outcomes",
      reliability_category == "Low Confidence" ~ "Requires manual review or additional data"
    )
  )

# Format as a professional table with kable()
kable(Summary_tbl, 
      align = c("l","l","l","l","l"), 
      col.names= c("County","Median Income","MOE (%)","Reliability Category", "Algorithm Implementation"), 
      caption = "Summary Table for County Reliability")
```

**Key Recommendations:**

**Your Task:** Use your analysis results to provide specific guidance to the department.

1. **Counties suitable for immediate algorithmic implementation:** 
These counties are appropriate for immediate algorithmic implementation because their MOE values are low, indicating high data reliability and minimizing the risk of biased or incorrect decisions.
```{r}
Counties_high <- PA_reliability %>%
  summarize(
    county = NAME,
    reliability_category = re_categories
  ) %>%
   filter(reliability_category == "High Confidence")

kable(Counties_high, 
      align = c("l","l"), 
      col.names= c("County","Reliability Category"), 
      caption = "Counties with High Confidence")
```


2. **Counties requiring additional oversight:** 
These counties have moderate confidence data, meaning their estimates carry more uncertainty, so algorithmic decisions should be closely monitored. These counties require regular data validation, manual review of algorithmic outputs, and targeted follow-up surveys to improve data reliability.
```{r}
Counties_high <- PA_reliability %>%
  summarize(
    county = NAME,
    reliability_category = re_categories
  ) %>%
   filter(reliability_category == "Moderate Confidence")

kable(Counties_high, 
      align = c("l","l"), 
      col.names= c("County","Reliability Category"), 
      caption = "Counties with Moderate Confidence")
```


3. **Counties needing alternative approaches:** 
In the Pennsylvania dataset I analyzed, no counties were classified as having low confidence. However, for any counties with low confidence data, these estimates should not be used directly for algorithmic decision-making. Instead, manual review and additional surveys should be implemented to improve the reliability of the data before it is used to inform decisions.

## Questions for Further Investigation

1. How have county and tract level MOE values changed over time when using ACS data from different years? Can we observe a decreasing trend in MOE, indicating that population and median income estimates are becoming more reliable over times?

2. How do MOE patterns vary across states, and is there a relationship between state-level economic indicators (e.g., GDP per capita) and the reliability of ACS data? Are states with stronger economies associated with lower MOE values and therefore more reliable data?

# Technical Notes

**Data Sources:** 
- U.S. Census Bureau, American Community Survey 2018-2022 5-Year Estimates
- Retrieved via tidycensus R package on 2025/9/26

**Reproducibility:** 
- All analysis conducted in R version 4.5.1
- Census API key required for replication
- Complete code and documentation available at: https://musa-5080-fall-2025.github.io/portfolio-setup-MarkD12138/assignments/assignment_1/assignment1.html

**Methodology Notes:**
This analysis focuses only on Pennsylvania counties as a case study, so the results may not fully represent national patterns. Additionally, I selected two example counties—one with high confidence and one with moderate confidence—to illustrate algorithmic decision-making implications. This selection is useful for demonstration but also limits the generalizability of the findings.

**Limitations:**
This analysis only uses data from Pennsylvania, which may not represent patterns across the entire U.S. Additionally, the analysis focuses on two selected counties, which limits the generalizability of the findings.

---

## Submission Checklist

Before submitting your portfolio link on Canvas:

- [ ] All code chunks run without errors
- [ ] All "[Fill this in]" prompts have been completed
- [ ] Tables are properly formatted and readable
- [ ] Executive summary addresses all four required components
- [ ] Portfolio navigation includes this assignment
- [ ] Census API key is properly set 
- [ ] Document renders correctly to HTML

**Remember:** Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/your_file_name.html`