{"title":"Assignment 5: Temporal Predictive Analysis","markdown":{"yaml":{"title":"Assignment 5: Temporal Predictive Analysis","subtitle":"Healthcare Access and Equity in Pennsylvania","author":"Zimu DENG (Mark)","date":"today","format":{"html":{"code-fold":false,"toc":true,"toc-location":"left","theme":"cosmo","embed-resources":true}},"execute":{"warning":false,"message":false}},"headingText":"1. Introduction","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo = TRUE,\n  warning = FALSE,\n  message = FALSE,\n  cache = TRUE\n)\n```\n\n\n## The Rebalancing Challenge in Philadelphia\n\nPhiladelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**. \n\nImagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have:\n- 200 stations across Philadelphia\n- Limited trucks and staff for moving bikes\n- 2-3 hours before morning rush hour demand peaks\n- **The question:** Which stations will run out of bikes by 8:30 AM?\n\nThis lab will build predictive models that forecast bike share demand across **Philadelphia**  and **2024, Q3** (different hours) to help solve this operational problem.\n\n## Learning Objectives\n\nBy the end of this assignment, I will be able to:\n\n1. **Understand panel data structure** for space-time analysis\n2. **Create temporal lag variables** to capture demand persistence\n3. **Build multiple predictive models** with increasing complexity\n4. **Validate models temporally** (train on past, test on future)\n5. **Analyze prediction errors** in both space and time\n6. **Engineer new features** based on error patterns\n7. **Critically evaluate** when prediction errors matter most\n\n---\n\n# 2. Setup\n\n## Load Libraries\n\n```{r load_libraries}\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# here!\nlibrary(here)\n# Get rid of scientific notation. We gotta look good!\noptions(scipen = 999)\n```\n\n## Define Themes\n\n```{r themes}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n\n## Set Census API Key\n\n```{r census_key, eval=FALSE}\n\ncensus_api_key(\"cd859f2a38103dda55948d92b3679de845f42f0f\", overwrite = TRUE, install = TRUE)\n\n```\n\n```{r census_key_hidden, include=FALSE}\n# Hidden key for rendering\ncensus_api_key(\"cd859f2a38103dda55948d92b3679de845f42f0f\")\n```\n\n---\n\n# Part 1\n\n# 3. Data Import & Preparation\n\n## Load Indego Trip Data (Q3 2024)\n\nDifferent quarters can be downloaded from: https://www.rideindego.com/about/data/\n\n```{r load_indego}\n# Read Q3 2024 data\nindego <- read_csv(\"data/indego-trips-2024-q3.csv\")\n\n# Quick look at the data\nglimpse(indego)\n```\n**Discussion:** I chose quarter 3 because I had previously analyzed Winter 2025 (Q1) and wanted to explore Summer patterns as well. Looking at Q3 allows me to compare seasonal differences in Philadelphia’s ridership and understand how demand shifts between winter and summer.\n\n## Examine the Data Structure\n\n```{r explore_data}\n# How many trips?\ncat(\"Total trips in Q3 2024:\", nrow(indego), \"\\n\")\n\n# Date range\ncat(\"Date range:\", \n    min(mdy_hm(indego$start_time)), \"to\", \n    max(mdy_hm(indego$start_time)), \"\\n\")\n\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego$start_station)), \"\\n\")\n\n# Trip types\ntable(indego$trip_route_category)\n\n# Passholder types\ntable(indego$passholder_type)\n\n# Bike types\ntable(indego$bike_type)\n```\n\n## Create Time Bins\n\nWe need to aggregate trips into hourly intervals for our panel data structure.\n\n```{r create_time_bins}\nSys.setlocale(\"LC_TIME\", \"C\")\n\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Look at temporal features\nhead(indego %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n---\n\n# 4. Exploratory Analysis\n\n## Trips Over Time\n\n```{r trips_over_time}\n# Daily trip counts\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q3 2024\",\n    subtitle = \"summer demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n**Discussion:** During Summer 2024, ridership in Philadelphia stays consistently high, with strong weekday peaks and lower weekend dips. The smoothed trend shows a slight decline in early summer, followed by a steady increase through August and September before dropping again at the start of October.\n \n```{r}\nfly_eagles_fly <- daily_trips %>% filter(date == \"2024-09-02\")\n\ntypical_boring_friday <- indego %>%\n  filter(dotw == \"Mon\", date != \"2024-09-02\") %>%\n  group_by(date) %>%\n  summarize(trips = n()) %>%\n  summarize(avg_Monday_trips = mean(trips))\n\nprint(fly_eagles_fly)\nprint(typical_boring_friday)\n\n```\n**Discussion:** September 2, 2024 was Labor Day in the United States, a major public holiday. Because Labor Day is a federal holiday, many people are off work, commute patterns drop sharply, and fewer riders use bike-share. As a result, daily ridership on September 2 is much lower than a typical Monday.\n\n## Hourly Patterns\n\n```{r hourly_patterns}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns, Q3 2024\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n**Discussion:** Peak hours occur around 8 AM and 5 PM on weekdays, showing a classic work-commute pattern. On weekends, the peaks shift later in the day and are much flatter—riders use the system more for leisure, with steady midday activity instead of sharp morning and evening spikes.\n\n## Top Stations\n\n```{r top_stations}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(20)\n\nkable(top_stations, \n      caption = \"Top 20 Indego Stations by Trip Origins\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n---\n\n# 5. Get Philadelphia Spatial Context\n\n## Load Philadelphia Census Data\n\nWe'll get census tract data to add demographic context to our stations.\n\n```{r load_census}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n\n# Check the data\nglimpse(philly_census)\n```\n\n## Map Philadelphia Context\n\n```{r map_philly}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n## Join Census Data to Stations\n\nWe'll spatially join census characteristics to each bike station.\n\n```{r join_census_to_stations}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n\n\n\n```\n\n# 6. Dealing with missing data\n\nWe need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them -- this is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations..\n\n\n```{r}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n```\n\n\n# 7. Get Weather Data\n\nWeather significantly affects bike share demand! Let's get hourly weather for Philadelphia.\n\n```{r get_weather}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q3 2024: July 1 - September 30\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-07-01\",\n  date_end = \"2024-09-30\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n## Visualize Weather Patterns\n\nWho is ready for a Philly summer?!\n\n```{r visualize_weather}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q3 2024\",\n    subtitle = \"Summer to early fall transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n---\n\n# 8. Create Space-Time Panel\n\n## Aggregate Trips to Station-Hour Level\n\n```{r aggregate_trips}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n\n# How many station-hour observations?\nnrow(trips_panel)\n\n# How many unique stations?\nlength(unique(trips_panel$start_station))\n\n# How many unique hours?\nlength(unique(trips_panel$interval60))\n```\n\n## Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n```{r complete_panel}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows, big.mark = \",\"), \"\\n\")\ncat(\"Current rows:\", format(nrow(trips_panel), big.mark = \",\"), \"\\n\")\ncat(\"Missing rows:\", format(expected_rows - nrow(trips_panel), big.mark = \",\"), \"\\n\")\n\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n\n# Verify we have complete panel\ncat(\"Complete panel rows:\", format(nrow(study_panel), big.mark = \",\"), \"\\n\")\n```\n\n## Add Time Features\n\n```{r add_time_features}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## Join Weather Data\n\n```{r join_weather}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n---\n\n# 9. Create Temporal Lag Variables\n\nThe key innovation for space-time prediction: **past demand predicts future demand**.\n\n## Why Lags?\n\nIf there were 15 bike trips from Station A at 8:00 AM, there will probably be ~15 trips at 9:00 AM. We can use this temporal persistence to improve predictions.\n\n```{r create_lags}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n## Visualize Lag Correlations\n\n```{r lag_correlations}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n---\n\n# 10. Temporal Train/Test Split\n\n**CRITICAL:** We must train on PAST data and test on FUTURE data!\n\n## Why Temporal Validation Matters\n\nIn real operations, at 6:00 AM on March 15, we need to predict demand for March 15-31. We have data from Jan 1 - March 14, but NOT from March 15-31 (it hasn't happened yet!).\n\n**Wrong approach:** Train on weeks 10-13, test on weeks 1-9 (predicting past from future!)\n\n**Correct approach:** Train on weeks 1-9, test on weeks 10-13 (predicting future from past)\n\n```{r temporal_split}\n# Split by week\n# Q3 has weeks 27-40 (July-Spet)\n# Train on weeks 27-35 \n# Test on weeks 36-40 \n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 36)\n\ntest <- study_panel_complete %>%\n  filter(week >= 36)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n\n\n\n\n\n\n```\n\n---\n\n# 11. Build Predictive Models\n\nWe'll build 5 models with increasing complexity to see what improves predictions.\n\n## Model 1: Baseline (Time + Weather)\n\n```{r model1}\n\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n\nsummary(model1)\n```\n\nThe model uses Monday as the baseline. Each coefficient represents the difference \nin expected trips per station-hour compared to Monday - dow_simple2 = Tuesday..\n\n**Weekday Pattern (Tue-Fri):**\n\n- All weekdays have positive coefficients (0.029 to 0.052)\n- Tuesday has the highest weekday effect (+0.052)\n- Weekdays likely benefit from concentrated commuting patterns\n\n**Weekend Pattern (Sat-Sun):**\n\n- Both weekend days have negative coefficients (-0.061 and -0.065)\n- This means FEWER trips per station-hour than Monday\n\n**Hourly Interpretation**\n\nHour   Coefficient   Interpretation\n0      (baseline)    0.000 trips/hour (midnight)\n1      -0.018       slightly fewer than midnight\n...\n6      +0.151       morning activity starting\n7      +0.276       morning rush building\n8      +0.487       PEAK morning rush\n9      +0.350       post-rush\n...\n17     +0.568       PEAK evening rush (5 PM!)\n18     +0.389       evening declining\n...\n23     +0.034       late night minimal\n\nIsn't this fun!\n\n## Model 2: Add Temporal Lags\n\n```{r model2}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n\nsummary(model2)\n```\n\n**Question:** Adding lags improve R². Adding lags improves R² because past ridership strongly predicts current ridership. Bike use is highly autocorrelated—if trips were high one hour (or one day) ago, they are likely to be high now as well.\n\n## Model 3: Add Demographics\n\n```{r model3}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\n\nsummary(model3)\n```\n\n## Model 4: Add Station Fixed Effects\n\n```{r model4}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\n**What do station fixed effects capture?** Baseline differences in demand across stations (some are just busier than others!).\n\n## Model 5: Add Rush Hour Interaction\n\n```{r model5}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n\ncat(\"Model 5 R-squared:\", summary(model5)$r.squared, \"\\n\")\ncat(\"Model 5 Adj R-squared:\", summary(model5)$adj.r.squared, \"\\n\")\n```\n\n---\n\n# 12. Model Evaluation\n\n## Calculate Predictions and MAE\n\n```{r calculate_mae}\n# Get predictions on test set\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Visualize Model Comparison\n\n```{r compare_models}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Discussion:** Which features gave us the biggest improvement?\nTemporal Lags\n\n---\n\n# 13. Compare Results to  Q1 2025\n\n## MAE Comparison\n```{r}\n## MAE comparison\nq1_mae <- c(0.60, 0.50, 0.74, 0.73, 0.73) ## Matrics from in-class exercise\n\nmae_compare <- data.frame(\n  Model  = mae_results$Model,\n  Q1_MAE = q1_mae,\n  Q3_MAE = mae_results$MAE   \n)\n\nkable(\n  mae_compare,\n  digits  = 2,\n  caption = \"Mean Absolute Error by Model: Q1 vs Q3 (Test Set)\",\n  col.names = c(\"Model\", \"Q1_MAE (trips)\", \"Q3_MAE (trips)\")\n) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Discussion:** Overall, Model 2 (model with Temporal Lags) has the lowest error in both Q1 and Q3. However, all models show higher errors in Q3, meaning that summer demand is harder to predict than winter demand. This suggests that temporal lags remain the strongest predictor across seasons, but Q3 likely needs additional features because bike usage is more variable in summer.\n\n## Temporal Patterns Comparison (summer vs. winter)\n```{r}\n## Comparison between Q1 2025 and Q3 2024 (summer vs. winter)\nlibrary(ggplot2)\nlibrary(png)\nlibrary(grid)\nlibrary(cowplot)\n\nimg1 <- png::readPNG(\"data/daily_ridership_Q3.png\")\np_left <- grid::rasterGrob(img1, interpolate = TRUE)\n\nimg2 <- png::readPNG(\"data/daily_ridership_Q1.png\")  \np_right <- grid::rasterGrob(img2, interpolate = TRUE)\n\ncowplot::plot_grid(\n  p_left,\n  p_right,\n  labels = c(\"summer vs. winter\"),\n  ncol = 2\n)\n\n```\n**Discussion:** Summer and winter show clearly different temporal ridership patterns. In summer (Q3 2024), daily trips stay consistently high, with strong weekday–weekend fluctuations and a pattern that rises through mid-season before gradually declining toward October. In contrast, winter (Q1 2025) begins at much lower levels and shows a steady upward trend as temperatures warm, with ridership recovering from January lows and climbing sharply into March and April. Overall, summer displays high, stable, and highly active demand, while winter reflects low but steadily increasing activity, capturing a clear seasonal effect in bike-share usage.\n\n\n## Important Features\n```{r}\n## Use partial R square to determine the  most important feature\nlibrary(rsq)\nrsq.partial(model2)\n```\n\n**Discussion:** In both Q1 and Q3, the one-hour lag (lag1Hour) is by far the most important predictor, followed by hour-of-day and the one-day lag. Weather and day-of-week contribute very little once temporal patterns and lags are included, and their independent explanatory power is even smaller in Q3.\n\n# Part 2\n\n# 14. Space-Time Error Analysis\n\n## Observed vs. Predicted\n\nLet's use our best model (Model 2) for error analysis.\n\n```{r obs_vs_pred}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n**Discussion:** The model performs best during low-demand periods—overnight and early morning—where observed trips are small and predictions stay close to the perfect-fit red line. It struggles the most during high-demand times like the AM and PM rush. In these periods, the model consistently underpredicts the highest trip volumes, as shown by the green line falling below the red line at larger values.\n\n## Spatial Error Patterns\n\nAre prediction errors clustered in certain parts of Philadelphia?\n\n```{r spatial_errors}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 0.8,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand  \np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 0.8,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hour)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n\n```\n\n**Question:** There is clear spatial clustering. The highest errors are concentrated in the high-demand areas of Philadelphia’s city center—especially around Center City and University City—where ridership is busiest and harder for the model to predict accurately.\n\n## Temporal Error Patterns\n\nWhen are we most wrong?\n\n```{r temporal_errors}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n## Errors and Demographics\n\nAre prediction errors related to neighborhood characteristics?\n\n```{r errors_demographics}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n**Discussion**: Errors tend to be slightly higher in higher-income and higher-percent-White neighborhoods, while they are lower in areas with high transit usage. This suggests the model struggles more in wealthier, less transit-oriented areas. The equity implication is that model performance is not uniform—some communities may receive less accurate predictions than others, which could affect planning decisions if not addressed.\n\n---\n\n# Part 3\n\n# 15. Feature Engineering: New Features\n\n## Spatial features\n```{r}\nlibrary(geosphere)\n\n## Distance to Center City\n\n# Center City coordinate (Use Philadelphia City Hall)\ncenter_lat <- 39.952800\ncenter_lon <- -75.163500\n\n# Calculate distance in kilometers\nstudy_panel_complete <- study_panel_complete %>%\n  mutate(\n    dist_to_center = distHaversine(\n      cbind(start_lon.y, start_lat.y),\n      cbind(center_lon, center_lat)\n    ) / 1000  # convert meters to km\n  )\n\n```\n\n## Trip history features\n```{r}\n## Rolling 7-day average demand\nlibrary(slider)\n\nstudy_panel_complete <- study_panel_complete %>%\n  arrange(start_station, date, hour) %>%\n  group_by(start_station) %>%\n  mutate(\n    rolling7 = slide_dbl(\n      Trip_Count,\n      mean,\n      .before = 168,\n      .complete = TRUE\n    )\n  ) %>%\n  ungroup()\n\n```\n\n# 16. Fit the New Model\n\n## Split train/test Dataset Again\n```{r}\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 36)\n\ntest <- study_panel_complete %>%\n  filter(week >= 36)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n\n```\n\n## Add two new presictors into the best model (previous model 2)\n```{r}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\nmodel_n <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + dist_to_center + rolling7,\n  data = train\n)\n\nsummary(model_n)\n```\n\n# 17. New Model Evaluation and MAE\n```{r}\n# Get predictions on test set\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred_n = predict(model_n, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results_new <- data.frame(\n  Model = c(\n    \"2. + Temporal Lags\",\n    \"New Model. + Rolling 7-day average demand and Distance to Center City\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred_n), na.rm = TRUE)\n  ),\n   RMSE = c(\n    sqrt(mean((test$Trip_Count - test$pred2)^2,  na.rm = TRUE)),\n    sqrt(mean((test$Trip_Count - test$pred_n)^2, na.rm = TRUE))\n  )\n)\n\nkable(mae_results_new, \n      digits = 5,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\", \"RMSE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Discussion:** Adding the two new features has very little impact on performance.\nCompared with the lag-only model, MAE increases slightly, meaning average errors get a bit worse, while RMSE decreases slightly, meaning the model fits large errors a bit better. Overall, the changes are tiny, so rolling 7-day demand and distance to Center City add only limited predictive power beyond the temporal lags.\n\n# 18.  Attempt of poisson model\n```{r}\n## Train a poisson model\nmodel_poisson <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + dist_to_center + rolling7,\n  family = poisson(link = \"log\"),\n  data   = train\n)\n\nsummary(model_poisson)\n```\n\n```{r}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n# 19. Evaluation of Poisson Model (MAE and RMSE)\n```{r}\ntest <- test %>%\n  mutate(\n    pred_pois = predict(model_poisson, newdata = test, type = \"response\")\n  )\n\n# Calculate MAE for each model\nmae_results_nn <- data.frame(\n  Model = c(\n    \"2. + Temporal Lags\",\n    \"New Model. + Rolling 7-day average demand and Distance to Center City\",\n    \"New Poisson Model\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred_n), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred_pois), na.rm = TRUE)\n  ),\n   RMSE = c(\n    sqrt(mean((test$Trip_Count - test$pred2)^2,  na.rm = TRUE)),\n    sqrt(mean((test$Trip_Count - test$pred_n)^2, na.rm = TRUE)),\n    sqrt(mean((test$Trip_Count - test$pred_pois)^2, na.rm = TRUE))\n  )\n)\n\nkable(mae_results_nn, \n      digits = 5,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\", \"RMSE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Discussion:** The Poisson model performs worse: both MAE and RMSE are higher than the lag-based linear models. \n\n## Part 4: Critical Reflection \n\nOur final MAE is moderate, which is still relatively large that Indego should be cautious about using this model for real-time rebalancing. The model often under-predicts during the highest demand periods, especially in the city center, so errors could translate directly into empty docks or no bikes when they are needed most. I would see this system as a useful decision-support tool for planning and for setting broad rebalancing priorities, but not as the only input for hourly truck routes. In practice, it should be combined with operator experience and live monitoring. The model also misses some important patterns: it cannot fully capture special events, holidays, or sudden weather changes, and it assumes that the relationships between predictors and demand stay stable over time (temporal stability). With more time and data, I would improve it by adding richer temporal and spatial features (e.g., event calendars, more detailed land-use and transit connections, longer history of ridership) and testing more flexible models that can capture nonlinear and complex effects.\n\nFrom an equity perspective, the error maps show that the largest errors occur in the highest-demand downtown neighborhoods, meaning the model is least accurate precisely where many riders rely on the system. If these biases are not addressed, the model could unintentionally worsen disparities—for example, by systematically under-serving busy core areas or misallocating bikes away from certain communities when predictions are wrong. To mitigate this, I would recommend regular fairness audits of prediction errors by neighborhood and demographic group, adding explicit equity targets or minimum-service constraints to any rebalancing strategy, and involving community feedback when evaluating model performance. This way, the system can support more efficient operations without sacrificing equitable access to bikes.\n\n---\n\n# Submission Requirements\n\n## What to Submit (per team)\n\n1. **Rmd file** with all your code (commented!)\n2. **HTML output** with results and visualizations\n3. **Brief report** summarizing (with supporting data & visualization):\n\n   - Your quarter and why you chose it\n   - Model comparison results\n   - Error analysis insights\n   - New features you added and why\n   - Critical reflection on deployment\n---","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo = TRUE,\n  warning = FALSE,\n  message = FALSE,\n  cache = TRUE\n)\n```\n\n# 1. Introduction\n\n## The Rebalancing Challenge in Philadelphia\n\nPhiladelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**. \n\nImagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have:\n- 200 stations across Philadelphia\n- Limited trucks and staff for moving bikes\n- 2-3 hours before morning rush hour demand peaks\n- **The question:** Which stations will run out of bikes by 8:30 AM?\n\nThis lab will build predictive models that forecast bike share demand across **Philadelphia**  and **2024, Q3** (different hours) to help solve this operational problem.\n\n## Learning Objectives\n\nBy the end of this assignment, I will be able to:\n\n1. **Understand panel data structure** for space-time analysis\n2. **Create temporal lag variables** to capture demand persistence\n3. **Build multiple predictive models** with increasing complexity\n4. **Validate models temporally** (train on past, test on future)\n5. **Analyze prediction errors** in both space and time\n6. **Engineer new features** based on error patterns\n7. **Critically evaluate** when prediction errors matter most\n\n---\n\n# 2. Setup\n\n## Load Libraries\n\n```{r load_libraries}\n# Core tidyverse\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Spatial data\nlibrary(sf)\nlibrary(tigris)\n\n# Census data\nlibrary(tidycensus)\n\n# Weather data\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# here!\nlibrary(here)\n# Get rid of scientific notation. We gotta look good!\noptions(scipen = 999)\n```\n\n## Define Themes\n\n```{r themes}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n\n## Set Census API Key\n\n```{r census_key, eval=FALSE}\n\ncensus_api_key(\"cd859f2a38103dda55948d92b3679de845f42f0f\", overwrite = TRUE, install = TRUE)\n\n```\n\n```{r census_key_hidden, include=FALSE}\n# Hidden key for rendering\ncensus_api_key(\"cd859f2a38103dda55948d92b3679de845f42f0f\")\n```\n\n---\n\n# Part 1\n\n# 3. Data Import & Preparation\n\n## Load Indego Trip Data (Q3 2024)\n\nDifferent quarters can be downloaded from: https://www.rideindego.com/about/data/\n\n```{r load_indego}\n# Read Q3 2024 data\nindego <- read_csv(\"data/indego-trips-2024-q3.csv\")\n\n# Quick look at the data\nglimpse(indego)\n```\n**Discussion:** I chose quarter 3 because I had previously analyzed Winter 2025 (Q1) and wanted to explore Summer patterns as well. Looking at Q3 allows me to compare seasonal differences in Philadelphia’s ridership and understand how demand shifts between winter and summer.\n\n## Examine the Data Structure\n\n```{r explore_data}\n# How many trips?\ncat(\"Total trips in Q3 2024:\", nrow(indego), \"\\n\")\n\n# Date range\ncat(\"Date range:\", \n    min(mdy_hm(indego$start_time)), \"to\", \n    max(mdy_hm(indego$start_time)), \"\\n\")\n\n# How many unique stations?\ncat(\"Unique start stations:\", length(unique(indego$start_station)), \"\\n\")\n\n# Trip types\ntable(indego$trip_route_category)\n\n# Passholder types\ntable(indego$passholder_type)\n\n# Bike types\ntable(indego$bike_type)\n```\n\n## Create Time Bins\n\nWe need to aggregate trips into hourly intervals for our panel data structure.\n\n```{r create_time_bins}\nSys.setlocale(\"LC_TIME\", \"C\")\n\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Look at temporal features\nhead(indego %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n---\n\n# 4. Exploratory Analysis\n\n## Trips Over Time\n\n```{r trips_over_time}\n# Daily trip counts\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q3 2024\",\n    subtitle = \"summer demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n**Discussion:** During Summer 2024, ridership in Philadelphia stays consistently high, with strong weekday peaks and lower weekend dips. The smoothed trend shows a slight decline in early summer, followed by a steady increase through August and September before dropping again at the start of October.\n \n```{r}\nfly_eagles_fly <- daily_trips %>% filter(date == \"2024-09-02\")\n\ntypical_boring_friday <- indego %>%\n  filter(dotw == \"Mon\", date != \"2024-09-02\") %>%\n  group_by(date) %>%\n  summarize(trips = n()) %>%\n  summarize(avg_Monday_trips = mean(trips))\n\nprint(fly_eagles_fly)\nprint(typical_boring_friday)\n\n```\n**Discussion:** September 2, 2024 was Labor Day in the United States, a major public holiday. Because Labor Day is a federal holiday, many people are off work, commute patterns drop sharply, and fewer riders use bike-share. As a result, daily ridership on September 2 is much lower than a typical Monday.\n\n## Hourly Patterns\n\n```{r hourly_patterns}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns, Q3 2024\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n**Discussion:** Peak hours occur around 8 AM and 5 PM on weekdays, showing a classic work-commute pattern. On weekends, the peaks shift later in the day and are much flatter—riders use the system more for leisure, with steady midday activity instead of sharp morning and evening spikes.\n\n## Top Stations\n\n```{r top_stations}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(20)\n\nkable(top_stations, \n      caption = \"Top 20 Indego Stations by Trip Origins\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n---\n\n# 5. Get Philadelphia Spatial Context\n\n## Load Philadelphia Census Data\n\nWe'll get census tract data to add demographic context to our stations.\n\n```{r load_census}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n\n# Check the data\nglimpse(philly_census)\n```\n\n## Map Philadelphia Context\n\n```{r map_philly}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n## Join Census Data to Stations\n\nWe'll spatially join census characteristics to each bike station.\n\n```{r join_census_to_stations}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n\n# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n\n\n\n```\n\n# 6. Dealing with missing data\n\nWe need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them -- this is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations..\n\n\n```{r}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n```\n\n\n# 7. Get Weather Data\n\nWeather significantly affects bike share demand! Let's get hourly weather for Philadelphia.\n\n```{r get_weather}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q3 2024: July 1 - September 30\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2024-07-01\",\n  date_end = \"2024-09-30\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  distinct()\n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n## Visualize Weather Patterns\n\nWho is ready for a Philly summer?!\n\n```{r visualize_weather}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q3 2024\",\n    subtitle = \"Summer to early fall transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n---\n\n# 8. Create Space-Time Panel\n\n## Aggregate Trips to Station-Hour Level\n\n```{r aggregate_trips}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n\n# How many station-hour observations?\nnrow(trips_panel)\n\n# How many unique stations?\nlength(unique(trips_panel$start_station))\n\n# How many unique hours?\nlength(unique(trips_panel$interval60))\n```\n\n## Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n```{r complete_panel}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows, big.mark = \",\"), \"\\n\")\ncat(\"Current rows:\", format(nrow(trips_panel), big.mark = \",\"), \"\\n\")\ncat(\"Missing rows:\", format(expected_rows - nrow(trips_panel), big.mark = \",\"), \"\\n\")\n\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n\n# Verify we have complete panel\ncat(\"Complete panel rows:\", format(nrow(study_panel), big.mark = \",\"), \"\\n\")\n```\n\n## Add Time Features\n\n```{r add_time_features}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n\n## Join Weather Data\n\n```{r join_weather}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n---\n\n# 9. Create Temporal Lag Variables\n\nThe key innovation for space-time prediction: **past demand predicts future demand**.\n\n## Why Lags?\n\nIf there were 15 bike trips from Station A at 8:00 AM, there will probably be ~15 trips at 9:00 AM. We can use this temporal persistence to improve predictions.\n\n```{r create_lags}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n## Visualize Lag Correlations\n\n```{r lag_correlations}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n---\n\n# 10. Temporal Train/Test Split\n\n**CRITICAL:** We must train on PAST data and test on FUTURE data!\n\n## Why Temporal Validation Matters\n\nIn real operations, at 6:00 AM on March 15, we need to predict demand for March 15-31. We have data from Jan 1 - March 14, but NOT from March 15-31 (it hasn't happened yet!).\n\n**Wrong approach:** Train on weeks 10-13, test on weeks 1-9 (predicting past from future!)\n\n**Correct approach:** Train on weeks 1-9, test on weeks 10-13 (predicting future from past)\n\n```{r temporal_split}\n# Split by week\n# Q3 has weeks 27-40 (July-Spet)\n# Train on weeks 27-35 \n# Test on weeks 36-40 \n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 36)\n\ntest <- study_panel_complete %>%\n  filter(week >= 36)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n\n\n\n\n\n\n```\n\n---\n\n# 11. Build Predictive Models\n\nWe'll build 5 models with increasing complexity to see what improves predictions.\n\n## Model 1: Baseline (Time + Weather)\n\n```{r model1}\n\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\n# Now run the model\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n\nsummary(model1)\n```\n\nThe model uses Monday as the baseline. Each coefficient represents the difference \nin expected trips per station-hour compared to Monday - dow_simple2 = Tuesday..\n\n**Weekday Pattern (Tue-Fri):**\n\n- All weekdays have positive coefficients (0.029 to 0.052)\n- Tuesday has the highest weekday effect (+0.052)\n- Weekdays likely benefit from concentrated commuting patterns\n\n**Weekend Pattern (Sat-Sun):**\n\n- Both weekend days have negative coefficients (-0.061 and -0.065)\n- This means FEWER trips per station-hour than Monday\n\n**Hourly Interpretation**\n\nHour   Coefficient   Interpretation\n0      (baseline)    0.000 trips/hour (midnight)\n1      -0.018       slightly fewer than midnight\n...\n6      +0.151       morning activity starting\n7      +0.276       morning rush building\n8      +0.487       PEAK morning rush\n9      +0.350       post-rush\n...\n17     +0.568       PEAK evening rush (5 PM!)\n18     +0.389       evening declining\n...\n23     +0.034       late night minimal\n\nIsn't this fun!\n\n## Model 2: Add Temporal Lags\n\n```{r model2}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\n\nsummary(model2)\n```\n\n**Question:** Adding lags improve R². Adding lags improves R² because past ridership strongly predicts current ridership. Bike use is highly autocorrelated—if trips were high one hour (or one day) ago, they are likely to be high now as well.\n\n## Model 3: Add Demographics\n\n```{r model3}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\n\nsummary(model3)\n```\n\n## Model 4: Add Station Fixed Effects\n\n```{r model4}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\n# Summary too long with all station dummies, just show key metrics\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\n**What do station fixed effects capture?** Baseline differences in demand across stations (some are just busier than others!).\n\n## Model 5: Add Rush Hour Interaction\n\n```{r model5}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n\ncat(\"Model 5 R-squared:\", summary(model5)$r.squared, \"\\n\")\ncat(\"Model 5 Adj R-squared:\", summary(model5)$adj.r.squared, \"\\n\")\n```\n\n---\n\n# 12. Model Evaluation\n\n## Calculate Predictions and MAE\n\n```{r calculate_mae}\n# Get predictions on test set\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n## Visualize Model Comparison\n\n```{r compare_models}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Discussion:** Which features gave us the biggest improvement?\nTemporal Lags\n\n---\n\n# 13. Compare Results to  Q1 2025\n\n## MAE Comparison\n```{r}\n## MAE comparison\nq1_mae <- c(0.60, 0.50, 0.74, 0.73, 0.73) ## Matrics from in-class exercise\n\nmae_compare <- data.frame(\n  Model  = mae_results$Model,\n  Q1_MAE = q1_mae,\n  Q3_MAE = mae_results$MAE   \n)\n\nkable(\n  mae_compare,\n  digits  = 2,\n  caption = \"Mean Absolute Error by Model: Q1 vs Q3 (Test Set)\",\n  col.names = c(\"Model\", \"Q1_MAE (trips)\", \"Q3_MAE (trips)\")\n) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Discussion:** Overall, Model 2 (model with Temporal Lags) has the lowest error in both Q1 and Q3. However, all models show higher errors in Q3, meaning that summer demand is harder to predict than winter demand. This suggests that temporal lags remain the strongest predictor across seasons, but Q3 likely needs additional features because bike usage is more variable in summer.\n\n## Temporal Patterns Comparison (summer vs. winter)\n```{r}\n## Comparison between Q1 2025 and Q3 2024 (summer vs. winter)\nlibrary(ggplot2)\nlibrary(png)\nlibrary(grid)\nlibrary(cowplot)\n\nimg1 <- png::readPNG(\"data/daily_ridership_Q3.png\")\np_left <- grid::rasterGrob(img1, interpolate = TRUE)\n\nimg2 <- png::readPNG(\"data/daily_ridership_Q1.png\")  \np_right <- grid::rasterGrob(img2, interpolate = TRUE)\n\ncowplot::plot_grid(\n  p_left,\n  p_right,\n  labels = c(\"summer vs. winter\"),\n  ncol = 2\n)\n\n```\n**Discussion:** Summer and winter show clearly different temporal ridership patterns. In summer (Q3 2024), daily trips stay consistently high, with strong weekday–weekend fluctuations and a pattern that rises through mid-season before gradually declining toward October. In contrast, winter (Q1 2025) begins at much lower levels and shows a steady upward trend as temperatures warm, with ridership recovering from January lows and climbing sharply into March and April. Overall, summer displays high, stable, and highly active demand, while winter reflects low but steadily increasing activity, capturing a clear seasonal effect in bike-share usage.\n\n\n## Important Features\n```{r}\n## Use partial R square to determine the  most important feature\nlibrary(rsq)\nrsq.partial(model2)\n```\n\n**Discussion:** In both Q1 and Q3, the one-hour lag (lag1Hour) is by far the most important predictor, followed by hour-of-day and the one-day lag. Weather and day-of-week contribute very little once temporal patterns and lags are included, and their independent explanatory power is even smaller in Q3.\n\n# Part 2\n\n# 14. Space-Time Error Analysis\n\n## Observed vs. Predicted\n\nLet's use our best model (Model 2) for error analysis.\n\n```{r obs_vs_pred}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n**Discussion:** The model performs best during low-demand periods—overnight and early morning—where observed trips are small and predictions stay close to the perfect-fit red line. It struggles the most during high-demand times like the AM and PM rush. In these periods, the model consistently underpredicts the highest trip volumes, as shown by the green line falling below the red line at larger values.\n\n## Spatial Error Patterns\n\nAre prediction errors clustered in certain parts of Philadelphia?\n\n```{r spatial_errors}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 0.8,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE (trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand  \np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.1) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 0.8,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg Demand (trips/hour)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\") +\n  mapTheme +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 12,\n    barheight = 1,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n\n```\n\n**Question:** There is clear spatial clustering. The highest errors are concentrated in the high-demand areas of Philadelphia’s city center—especially around Center City and University City—where ridership is busiest and harder for the model to predict accurately.\n\n## Temporal Error Patterns\n\nWhen are we most wrong?\n\n```{r temporal_errors}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n## Errors and Demographics\n\nAre prediction errors related to neighborhood characteristics?\n\n```{r errors_demographics}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n**Discussion**: Errors tend to be slightly higher in higher-income and higher-percent-White neighborhoods, while they are lower in areas with high transit usage. This suggests the model struggles more in wealthier, less transit-oriented areas. The equity implication is that model performance is not uniform—some communities may receive less accurate predictions than others, which could affect planning decisions if not addressed.\n\n---\n\n# Part 3\n\n# 15. Feature Engineering: New Features\n\n## Spatial features\n```{r}\nlibrary(geosphere)\n\n## Distance to Center City\n\n# Center City coordinate (Use Philadelphia City Hall)\ncenter_lat <- 39.952800\ncenter_lon <- -75.163500\n\n# Calculate distance in kilometers\nstudy_panel_complete <- study_panel_complete %>%\n  mutate(\n    dist_to_center = distHaversine(\n      cbind(start_lon.y, start_lat.y),\n      cbind(center_lon, center_lat)\n    ) / 1000  # convert meters to km\n  )\n\n```\n\n## Trip history features\n```{r}\n## Rolling 7-day average demand\nlibrary(slider)\n\nstudy_panel_complete <- study_panel_complete %>%\n  arrange(start_station, date, hour) %>%\n  group_by(start_station) %>%\n  mutate(\n    rolling7 = slide_dbl(\n      Trip_Count,\n      mean,\n      .before = 168,\n      .complete = TRUE\n    )\n  ) %>%\n  ungroup()\n\n```\n\n# 16. Fit the New Model\n\n## Split train/test Dataset Again\n```{r}\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 36) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 36)\n\ntest <- study_panel_complete %>%\n  filter(week >= 36)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n\n```\n\n## Add two new presictors into the best model (previous model 2)\n```{r}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\nmodel_n <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + dist_to_center + rolling7,\n  data = train\n)\n\nsummary(model_n)\n```\n\n# 17. New Model Evaluation and MAE\n```{r}\n# Get predictions on test set\n\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred_n = predict(model_n, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results_new <- data.frame(\n  Model = c(\n    \"2. + Temporal Lags\",\n    \"New Model. + Rolling 7-day average demand and Distance to Center City\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred_n), na.rm = TRUE)\n  ),\n   RMSE = c(\n    sqrt(mean((test$Trip_Count - test$pred2)^2,  na.rm = TRUE)),\n    sqrt(mean((test$Trip_Count - test$pred_n)^2, na.rm = TRUE))\n  )\n)\n\nkable(mae_results_new, \n      digits = 5,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\", \"RMSE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Discussion:** Adding the two new features has very little impact on performance.\nCompared with the lag-only model, MAE increases slightly, meaning average errors get a bit worse, while RMSE decreases slightly, meaning the model fits large errors a bit better. Overall, the changes are tiny, so rolling 7-day demand and distance to Center City add only limited predictive power beyond the temporal lags.\n\n# 18.  Attempt of poisson model\n```{r}\n## Train a poisson model\nmodel_poisson <- glm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + dist_to_center + rolling7,\n  family = poisson(link = \"log\"),\n  data   = train\n)\n\nsummary(model_poisson)\n```\n\n```{r}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n# 19. Evaluation of Poisson Model (MAE and RMSE)\n```{r}\ntest <- test %>%\n  mutate(\n    pred_pois = predict(model_poisson, newdata = test, type = \"response\")\n  )\n\n# Calculate MAE for each model\nmae_results_nn <- data.frame(\n  Model = c(\n    \"2. + Temporal Lags\",\n    \"New Model. + Rolling 7-day average demand and Distance to Center City\",\n    \"New Poisson Model\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred_n), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred_pois), na.rm = TRUE)\n  ),\n   RMSE = c(\n    sqrt(mean((test$Trip_Count - test$pred2)^2,  na.rm = TRUE)),\n    sqrt(mean((test$Trip_Count - test$pred_n)^2, na.rm = TRUE)),\n    sqrt(mean((test$Trip_Count - test$pred_pois)^2, na.rm = TRUE))\n  )\n)\n\nkable(mae_results_nn, \n      digits = 5,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\", \"RMSE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n**Discussion:** The Poisson model performs worse: both MAE and RMSE are higher than the lag-based linear models. \n\n## Part 4: Critical Reflection \n\nOur final MAE is moderate, which is still relatively large that Indego should be cautious about using this model for real-time rebalancing. The model often under-predicts during the highest demand periods, especially in the city center, so errors could translate directly into empty docks or no bikes when they are needed most. I would see this system as a useful decision-support tool for planning and for setting broad rebalancing priorities, but not as the only input for hourly truck routes. In practice, it should be combined with operator experience and live monitoring. The model also misses some important patterns: it cannot fully capture special events, holidays, or sudden weather changes, and it assumes that the relationships between predictors and demand stay stable over time (temporal stability). With more time and data, I would improve it by adding richer temporal and spatial features (e.g., event calendars, more detailed land-use and transit connections, longer history of ridership) and testing more flexible models that can capture nonlinear and complex effects.\n\nFrom an equity perspective, the error maps show that the largest errors occur in the highest-demand downtown neighborhoods, meaning the model is least accurate precisely where many riders rely on the system. If these biases are not addressed, the model could unintentionally worsen disparities—for example, by systematically under-serving busy core areas or misallocating bikes away from certain communities when predictions are wrong. To mitigate this, I would recommend regular fairness audits of prediction errors by neighborhood and demographic group, adding explicit equity targets or minimum-service constraints to any rebalancing strategy, and involving community feedback when evaluating model performance. This way, the system can support more efficient operations without sacrificing equitable access to bikes.\n\n---\n\n# Submission Requirements\n\n## What to Submit (per team)\n\n1. **Rmd file** with all your code (commented!)\n2. **HTML output** with results and visualizations\n3. **Brief report** summarizing (with supporting data & visualization):\n\n   - Your quarter and why you chose it\n   - Model comparison results\n   - Error analysis insights\n   - New features you added and why\n   - Critical reflection on deployment\n---"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"embed-resources":true,"output-file":"assignment5.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","title":"Assignment 5: Temporal Predictive Analysis","subtitle":"Healthcare Access and Equity in Pennsylvania","author":"Zimu DENG (Mark)","date":"today","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}